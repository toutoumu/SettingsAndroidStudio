<application>
  <component name="AppStorage">
    <option name="newTranslationDialogHeight" value="387" />
    <option name="newTranslationDialogWidth" value="835" />
    <option name="newTranslationDialogX" value="331" />
    <option name="newTranslationDialogY" value="245" />
    <option name="pinNewTranslationDialog" value="true" />
    <histories>
      <item value="generate" />
      <item value="generated" />
      <item value="generic" />
      <item value="Sets the rotation that the intended target resolution is expressed in. &lt;p&gt;This sets the rotation that is used when specifying a target resolution using {@link setTargetResolution(Size)}, which accepts a resolution at the target orientation. &lt;p&gt;rotation is one of four valid values: {@link SurfaceROTATION_0}, {@link SurfaceROTATION_90}, {@link SurfaceROTATION_180}, {@link SurfaceROTATION_270}. Rotation values are relative to the &quot;natural&quot; rotation, {@link SurfaceROTATION_0}. &lt;p&gt;For example a portrait natural device may specify a portrait image target resolution as 480x640, and the same device rotated to and displaying in landscape (i.e. as returned by {@link DisplaygetRotation()}) may set the target rotation to {@link SurfaceROTATION_90} and resolution to 640x480. &lt;p&gt;If not set, the target rotation will default to the value of {@link DisplaygetRotation()} of the default display at the time the use case is created. The use case is fully created once it has been attached to a camera. &lt;p&gt; Note that {@link SurfaceView} does not support non-display rotation. If the target rotation is different than the value of {@link DisplaygetRotation()}, {@link SurfaceView} should not be used to provide the {@link Surface} in {@link SurfaceRequestprovideSurface(Surface, Executor, Consumer)} @param rotation The rotation of the intended target. @return The current Builder. @see setTargetResolution(Size)" />
      <item value="Set initial target rotation, we will have to call this again if rotation changes during the lifecycle of this use case" />
      <item value="Custom View that displays the camera feed for CameraX's {@link Preview} use case. &lt;p&gt; This class manages the preview {@link Surface}'s lifecycle. It internally uses either a {@link TextureView} or {@link SurfaceView} to display the camera feed, and applies required transformations on them to correctly display the preview, this involves correcting their aspect ratio, scale and rotation. &lt;p&gt; If {@link PreviewView} uses a {@link SurfaceView} to display the preview stream, be careful when overlapping a {@link View} that's initially not visible (either {@link ViewINVISIBLE} or {@link ViewGONE}) on top of it. When the {@link SurfaceView} is attached to the display window, it calls {@link android.view.ViewParentrequestTransparentRegion(View)} which requests a computation of the transparent regions on the display. At this point, the {@link View} isn't visible, causing the overlapped region between the {@link SurfaceView} and the {@link View} to be considered transparent. Later if the {@link View} becomes {@linkplain ViewVISIBLE visible}, it will not be displayed on top of {@link SurfaceView}. A way around this is to call {@link android.view.ViewParentrequestTransparentRegion(View)} right after making the {@link View} visible, or initially hiding the {@link View} by setting its {@linkplain ViewsetAlpha(float) opacity} to 0, then setting it to 1.0F to show it." />
      <item value="TORCH" />
      <item value="&lt;p&gt;Whether auto-white balance (AWB) is currently setting the color transform fields, and what its illumination target is.&lt;p&gt; &lt;p&gt;This control is only effective if {@link CaptureRequestCONTROL_MODE android.control.mode} is AUTO.&lt;p&gt; &lt;p&gt;When set to the ON mode, the camera device's auto-white balance routine is enabled, overriding the application's selected {@link CaptureRequestCOLOR_CORRECTION_TRANSFORM android.colorCorrection.transform}, {@link CaptureRequestCOLOR_CORRECTION_GAINS android.colorCorrection.gains} and {@link CaptureRequestCOLOR_CORRECTION_MODE android.colorCorrection.mode}. Note that when {@link CaptureRequestCONTROL_AE_MODE android.control.aeMode} is OFF, the behavior of AWB is device dependent. It is recommened to also set AWB mode to OFF or lock AWB by using {@link CaptureRequestCONTROL_AWB_LOCK android.control.awbLock} before setting AE mode to OFF.&lt;p&gt; &lt;p&gt;When set to the OFF mode, the camera device's auto-white balance routine is disabled. The application manually controls the white balance by {@link CaptureRequestCOLOR_CORRECTION_TRANSFORM android.colorCorrection.transform}, {@link CaptureRequestCOLOR_CORRECTION_GAINS android.colorCorrection.gains} and {@link CaptureRequestCOLOR_CORRECTION_MODE android.colorCorrection.mode}.&lt;p&gt; &lt;p&gt;When set to any other modes, the camera device's auto-white balance routine is disabled. The camera device uses each particular illumination target for white balance adjustment. The application's values for" />
      <item value="CONTROL AWB MODE" />
      <item value="CONTROL MODE" />
      <item value="CONTROL AE TARGET FPS RANGE" />
      <item value="PREVIEW EFFECT SOLARIZE" />
      <item value="PREVIEW EFFECT MONO" />
      <item value="SENSOR PRESET LANDSCAPE" />
      <item value="SENSOR PRESET PORTRAIT" />
      <item value="SENSOR PRESET ACTION" />
      <item value="SCALER STREAM CONFIGURATION MAP" />
      <item value="camera image Mega Pixels" />
      <item value="Default zoom. Accepts a float representing the factor to zoom by." />
      <item value="coroutines" />
      <item value="PREPARATION PHARMACY" />
      <item value="ONLINE SHOPPING MALL QUICK" />
      <item value="attach" />
      <item value="图片浏览器" />
      <item value="Glide uses it's own default tag id, so there's no need to specify your own. This method will be removed in a future version." />
      <item value="Indicates data was retrieved from the in memory cache." />
      <item value="if" />
      <item value="39164794512" />
      <item value="(Optional) Row bytes of each image plane. If yuv contains padding, the stride of each image must be provided. If strides is null, the method assumes no padding and derives the row bytes by format and width itself." />
      <item value="remaining" />
      <item value="Get the array of pixel planes for this Image. The number of planes is determined by the format of the Image. The application will get an empty array if the image format is {@link android.graphics.ImageFormatPRIVATE PRIVATE}, because the image pixel data is not directly accessible. The application can check the image format by calling" />
      <item value="byte array containing the YUV data. If the format has more than one planes, they must be concatenated" />
      <item value="byte array containing the YUV data. If the format has more than one planes, they must be concatenated." />
      <item value="If set to a value &gt; 1, requests the decoder to subsample the original image, returning a smaller image to save memory. The sample size is the number of pixels in either dimension that correspond to a single pixel in the decoded bitmap. For example, inSampleSize == 4 returns an image that is 14 the widthheight of the original, and 116 the number of pixels. Any value &lt;= 1 is treated the same as 1. Note: the decoder uses a final value based on powers of 2, any other value will be rounded down to the nearest power of 2." />
      <item value="Keep aspect ratio if one dimension is set to 0" />
      <item value="compress" />
      <item value="ExifInterface supports the HEIF format on OMR1+. Glide's {@link DefaultImageHeaderParser} doesn't currently support HEIF. In the future we should reconcile these two classes, but for now this is a simple way to ensure that HEIF files are oriented correctly on platforms where they're supported." />
      <item value="Stop the heif writer synchronously. Throws exception if the writer didn't finish writing successfully. Upon a success return: - For buffer and bitmap inputs, all images sent before stop will be written. - For surface input, images with timestamp on or before that specified in {@link setInputEndOfStreamTimestamp(long)} will be written. In case where {@link setInputEndOfStreamTimestamp(long)} was never called, stop will block until maximum number of images are received. @param timeoutMs Maximum time (in microsec) to wait for the writer to complete, with zero indicating waiting indefinitely. @see setInputEndOfStreamTimestamp(long) @throws Exception if encountered error, in which case the output file may not be valid. In particular, {@link TimeoutException} is thrown when timed out, and {@link MediaCodec.CodecException} is thrown when encountered codec error." />
      <item value="synchronously" />
      <item value="oval" />
      <item value="transparent" />
      <item value="透明" />
      <item value="Called when a load completes successfully, immediately before" />
      <item value="14:05 File type recognized: File extension .analysis_options was reassigned to YAML Revert" />
      <item value="Accelerate Decelerate Interpolator" />
      <item value="exclude From Recents" />
      <item value="SYSTEM UI FLAG IMMERSIVE STICKY" />
      <item value="Create a waveform vibration. Waveform vibrations are a potentially repeating series of timing and amplitude pairs. For each pair, the value in the amplitude array determines the strength of the vibration and the value in the timing array determines how long it vibrates for. An amplitude of 0 implies no vibration (i.e. off), and any pairs with a timing value of 0 will be ignored. &lt;p&gt; The amplitude array of the generated waveform will be the same size as the given timing array with alternating values of 0 (i.e. off) and {@link DEFAULT_AMPLITUDE}, starting with 0. Therefore the first timing value will be the period to wait before turning the vibrator on, the second value will be how long to vibrate at {@link DEFAULT_AMPLITUDE} strength, etc. &lt;p&gt;&lt;p&gt; To cause the pattern to repeat, pass the index into the timings array at which to start the repetition, or -1 to disable repeating. &lt;p&gt;" />
      <item value="amplitude" />
      <item value="PARCEL TOKEN WAVEFORM" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="910" />
        <entry key="ENGLISH" value="911" />
        <entry key="ESTONIAN" value="1" />
        <entry key="AFRIKAANS" value="1" />
        <entry key="DANISH" value="4" />
        <entry key="GERMAN" value="1" />
        <entry key="FRENCH" value="2" />
        <entry key="DUTCH" value="1" />
        <entry key="CATALAN" value="1" />
        <entry key="LATIN" value="2" />
        <entry key="ROMANIAN" value="1" />
        <entry key="BENGALI" value="2" />
        <entry key="PORTUGUESE" value="2" />
        <entry key="ITALIAN" value="1" />
        <entry key="INDONESIAN" value="1" />
      </map>
    </option>
  </component>
  <component name="Cache">
    <option name="lastTrimTime" value="1629250197797" />
  </component>
</application>