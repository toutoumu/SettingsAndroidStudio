<application>
  <component name="AppStorage">
    <option name="newTranslationDialogHeight" value="387" />
    <option name="newTranslationDialogWidth" value="835" />
    <option name="newTranslationDialogX" value="331" />
    <option name="newTranslationDialogY" value="245" />
    <option name="pinNewTranslationDialog" value="true" />
    <histories>
      <item value="Update session configuration and possibly reconfigure session." />
      <item value="Sets the desired rotation of the output image. &lt;p&gt;This will affect the EXIF rotation metadata in images saved by takePicture calls and the {@link ImageInfogetRotationDegrees()} value of the {@link ImageProxy} returned by {@link OnImageCapturedCallback}. These will be set to be the rotation, which if applied to the output image data, will make the image match target rotation specified here. &lt;p&gt;While rotation can also be set via {@link BuildersetTargetRotation(int)}, using {@link ImageCapturesetTargetRotation(int)} allows the target rotation to be set dynamically. &lt;p&gt;In general, it is best to use an {@link android.view.OrientationEventListener} to set the target rotation. This way, the rotation output will indicate which way is down for a given image. This is important since display orientation may be locked by device default, user setting, or app configuration, and some devices may not transition to a reverse-portrait display orientation. In these cases, use {@link ImageCapturesetTargetRotation} to set target rotation dynamically according to the {@link android.view.OrientationEventListener}, without re-creating the use case. Note the OrientationEventListener output of degrees in the range [0..359] should be converted to a surface rotation. The mapping values are listed as the following. &lt;p&gt;{@link android.view.OrientationEventListenerORIENTATION_UNKNOWN}: orientation == -1 &lt;p&gt;{@link SurfaceROTATION_0}: orientation &gt;= 315 || orientation &lt; 45 &lt;p&gt;{@link SurfaceROTATION_90}: orientation &gt;= 225 &amp;&amp; orientation &lt; 315 &lt;p&gt;{@link SurfaceROTATION_180}: orientation &gt;= 135 &amp;&amp; orientation &lt; 225 &lt;p&gt;{@link SurfaceROTATION_270}: orientation &gt;= 45 &amp;&amp; orientation &lt; 135 &lt;p&gt;When this function is called, value set by {@link ImageCapture.BuildersetTargetResolution(Size)} will be updated automatically to make sure the suitable resolution can be selected when the use case is bound. Value set by {@link ImageCapturesetCropAspectRatio(Rational)} will also be updated automatically to make sure the output image is cropped into expected aspect ratio. &lt;p&gt;If no target rotation is set by the application, it is set to the value of {@link DisplaygetRotation()} of the default display at the time the use case is created. The use case is fully created once it has been attached to a camera. &lt;p&gt;takePicture uses the target rotation at the time it begins executing (which may be delayed waiting on a previous takePicture call to complete). @param rotation Target rotation of the output image, expressed as one of {@link SurfaceROTATION_0}, {@link SurfaceROTATION_90}, {@link SurfaceROTATION_180}, or {@link SurfaceROTATION_270}." />
      <item value="Sets the desired rotation of the output image. &lt;p&gt;This will affect the EXIF rotation metadata in images saved by takePicture calls and the {@link ImageInfogetRotationDegrees()} value of the {@link ImageProxy} returned by {@link OnImageCapturedCallback}. These will be set to be the rotation, which if applied to the output image data, will make the image match target rotation specified here. &lt;p&gt;While rotation can also be set via {@link BuildersetTargetRotation(int)}, using {@link ImageCapturesetTargetRotation(int)} allows the target rotation to be set dynamically. &lt;p&gt;In general, it is best to use an {@link android.view.OrientationEventListener} to set the target rotation. This way, the rotation output will indicate which way is down for a given image. This is important since display orientation may be locked by device default, user setting, or app configuration, and some devices may not transition to a reverse-portrait display orientation. In these cases, use {@link ImageCapturesetTargetRotation} to set target rotation dynamically according to the {@link android.view.OrientationEventListener}, without re-creating the use case. Note the OrientationEventListener output of degrees in the range [0..359] should be converted to a surface rotation. The mapping values are listed as the following. &lt;p&gt;{@link android.view.OrientationEventListenerORIENTATION_UNKNOWN}: orientation == -1 &lt;p&gt;{@link SurfaceROTATION_0}: orientation &gt;= 315 || orientation &lt; 45 &lt;p&gt;{@link SurfaceROTATION_90}: orientation &gt;= 225 &amp;&amp; orientation &lt; 315 &lt;p&gt;{@link SurfaceROTATION_180}: orientation &gt;= 135 &amp;&amp; orientation &lt; 225 &lt;p&gt;{@link SurfaceROTATION_270}: orientation &gt;= 45 &amp;&amp; orientation &lt; 135 &lt;p&gt;When this function is called, value set by {@link ImageCapture.BuildersetTargetResolution(Size)} will be updated automatically to make sure the suitable resolution can be selected when the use case is bound. Value set by {@link ImageCapturesetCropAspectRatio(Rational)} will also be updated automatically to make sure the output image is cropped into expected aspect ratio. &lt;p&gt;If no target rotation is set by the application, it is set to the value of {@link DisplaygetRotation()} of the default display at the time the use case is created. The use case is fully created once it has been attached to a camera. &lt;p&gt;takePicture uses the target rotation at the time it begins executing (which may be delayed waiting on a previous takePicture call to complete)." />
      <item value="&lt;p&gt;The orientation for a JPEG image.&lt;p&gt; &lt;p&gt;The clockwise rotation angle in degrees, relative to the orientation to the camera, that the JPEG picture needs to be rotated by, to be viewed upright.&lt;p&gt; &lt;p&gt;Camera devices may either encode this value into the JPEG EXIF header, or rotate the image data to match this orientation. When the image data is rotated, the thumbnail data will also be rotated.&lt;p&gt; &lt;p&gt;Note that this orientation is relative to the orientation of the camera sensor, given by {@link CameraCharacteristicsSENSOR_ORIENTATION android.sensor.orientation}.&lt;p&gt; &lt;p&gt;To translate from the device orientation given by the Android sensor APIs for camera sensors which are not EXTERNAL, the following sample code may be used:&lt;p&gt; &lt;pre&gt;&lt;code&gt;private int getJpegOrientation(CameraCharacteristics c, int deviceOrientation) { if (deviceOrientation == android.view.OrientationEventListener.ORIENTATION_UNKNOWN) return 0; int sensorOrientation = c.get(CameraCharacteristics.SENSOR_ORIENTATION); Round device orientation to a multiple of 90 deviceOrientation = (deviceOrientation + 45) 90 90; Reverse device orientation for front-facing cameras boolean facingFront = c.get(CameraCharacteristics.LENS_FACING) == CameraCharacteristics.LENS_FACING_FRONT; if (facingFront) deviceOrientation = -deviceOrientation; Calculate desired JPEG orientation relative to camera orientation to make the image upright relative to the device orientation int jpegOrientation = (sensorOrientation + deviceOrientation + 360) % 360; return jpegOrientation; } &lt;code&gt;&lt;pre&gt; &lt;p&gt;For EXTERNAL cameras the sensor orientation will always be set to 0 and the facing will also be set to EXTERNAL. The above code is not relevant in such case.&lt;p&gt; &lt;p&gt;This tag is also used to describe the orientation of the HEIC image capture, in which case the rotation is reflected by {@link android.media.ExifInterfaceTAG_ORIENTATION EXIF orientation flag}, and not by rotating the image data itself.&lt;p&gt; &lt;p&gt;&lt;b&gt;Units&lt;b&gt;: Degrees in multiples of 90&lt;p&gt; &lt;p&gt;&lt;b&gt;Range of valid values:&lt;b&gt;&lt;br&gt; 0, 90, 180, 270&lt;p&gt; &lt;p&gt;This key is available on all devices.&lt;p&gt; @see C" />
      <item value="generate" />
      <item value="generated" />
      <item value="generic" />
      <item value="Sets the rotation that the intended target resolution is expressed in. &lt;p&gt;This sets the rotation that is used when specifying a target resolution using {@link setTargetResolution(Size)}, which accepts a resolution at the target orientation. &lt;p&gt;rotation is one of four valid values: {@link SurfaceROTATION_0}, {@link SurfaceROTATION_90}, {@link SurfaceROTATION_180}, {@link SurfaceROTATION_270}. Rotation values are relative to the &quot;natural&quot; rotation, {@link SurfaceROTATION_0}. &lt;p&gt;For example a portrait natural device may specify a portrait image target resolution as 480x640, and the same device rotated to and displaying in landscape (i.e. as returned by {@link DisplaygetRotation()}) may set the target rotation to {@link SurfaceROTATION_90} and resolution to 640x480. &lt;p&gt;If not set, the target rotation will default to the value of {@link DisplaygetRotation()} of the default display at the time the use case is created. The use case is fully created once it has been attached to a camera. &lt;p&gt; Note that {@link SurfaceView} does not support non-display rotation. If the target rotation is different than the value of {@link DisplaygetRotation()}, {@link SurfaceView} should not be used to provide the {@link Surface} in {@link SurfaceRequestprovideSurface(Surface, Executor, Consumer)} @param rotation The rotation of the intended target. @return The current Builder. @see setTargetResolution(Size)" />
      <item value="Set initial target rotation, we will have to call this again if rotation changes during the lifecycle of this use case" />
      <item value="Custom View that displays the camera feed for CameraX's {@link Preview} use case. &lt;p&gt; This class manages the preview {@link Surface}'s lifecycle. It internally uses either a {@link TextureView} or {@link SurfaceView} to display the camera feed, and applies required transformations on them to correctly display the preview, this involves correcting their aspect ratio, scale and rotation. &lt;p&gt; If {@link PreviewView} uses a {@link SurfaceView} to display the preview stream, be careful when overlapping a {@link View} that's initially not visible (either {@link ViewINVISIBLE} or {@link ViewGONE}) on top of it. When the {@link SurfaceView} is attached to the display window, it calls {@link android.view.ViewParentrequestTransparentRegion(View)} which requests a computation of the transparent regions on the display. At this point, the {@link View} isn't visible, causing the overlapped region between the {@link SurfaceView} and the {@link View} to be considered transparent. Later if the {@link View} becomes {@linkplain ViewVISIBLE visible}, it will not be displayed on top of {@link SurfaceView}. A way around this is to call {@link android.view.ViewParentrequestTransparentRegion(View)} right after making the {@link View} visible, or initially hiding the {@link View} by setting its {@linkplain ViewsetAlpha(float) opacity} to 0, then setting it to 1.0F to show it." />
      <item value="TORCH" />
      <item value="&lt;p&gt;Whether auto-white balance (AWB) is currently setting the color transform fields, and what its illumination target is.&lt;p&gt; &lt;p&gt;This control is only effective if {@link CaptureRequestCONTROL_MODE android.control.mode} is AUTO.&lt;p&gt; &lt;p&gt;When set to the ON mode, the camera device's auto-white balance routine is enabled, overriding the application's selected {@link CaptureRequestCOLOR_CORRECTION_TRANSFORM android.colorCorrection.transform}, {@link CaptureRequestCOLOR_CORRECTION_GAINS android.colorCorrection.gains} and {@link CaptureRequestCOLOR_CORRECTION_MODE android.colorCorrection.mode}. Note that when {@link CaptureRequestCONTROL_AE_MODE android.control.aeMode} is OFF, the behavior of AWB is device dependent. It is recommened to also set AWB mode to OFF or lock AWB by using {@link CaptureRequestCONTROL_AWB_LOCK android.control.awbLock} before setting AE mode to OFF.&lt;p&gt; &lt;p&gt;When set to the OFF mode, the camera device's auto-white balance routine is disabled. The application manually controls the white balance by {@link CaptureRequestCOLOR_CORRECTION_TRANSFORM android.colorCorrection.transform}, {@link CaptureRequestCOLOR_CORRECTION_GAINS android.colorCorrection.gains} and {@link CaptureRequestCOLOR_CORRECTION_MODE android.colorCorrection.mode}.&lt;p&gt; &lt;p&gt;When set to any other modes, the camera device's auto-white balance routine is disabled. The camera device uses each particular illumination target for white balance adjustment. The application's values for" />
      <item value="CONTROL AWB MODE" />
      <item value="CONTROL MODE" />
      <item value="CONTROL AE TARGET FPS RANGE" />
      <item value="PREVIEW EFFECT SOLARIZE" />
      <item value="PREVIEW EFFECT MONO" />
      <item value="SENSOR PRESET LANDSCAPE" />
      <item value="SENSOR PRESET PORTRAIT" />
      <item value="SENSOR PRESET ACTION" />
      <item value="SCALER STREAM CONFIGURATION MAP" />
      <item value="camera image Mega Pixels" />
      <item value="Default zoom. Accepts a float representing the factor to zoom by." />
      <item value="coroutines" />
      <item value="PREPARATION PHARMACY" />
      <item value="ONLINE SHOPPING MALL QUICK" />
      <item value="attach" />
      <item value="图片浏览器" />
      <item value="Glide uses it's own default tag id, so there's no need to specify your own. This method will be removed in a future version." />
      <item value="Indicates data was retrieved from the in memory cache." />
      <item value="if" />
      <item value="39164794512" />
      <item value="(Optional) Row bytes of each image plane. If yuv contains padding, the stride of each image must be provided. If strides is null, the method assumes no padding and derives the row bytes by format and width itself." />
      <item value="remaining" />
      <item value="Get the array of pixel planes for this Image. The number of planes is determined by the format of the Image. The application will get an empty array if the image format is {@link android.graphics.ImageFormatPRIVATE PRIVATE}, because the image pixel data is not directly accessible. The application can check the image format by calling" />
      <item value="byte array containing the YUV data. If the format has more than one planes, they must be concatenated" />
      <item value="byte array containing the YUV data. If the format has more than one planes, they must be concatenated." />
      <item value="If set to a value &gt; 1, requests the decoder to subsample the original image, returning a smaller image to save memory. The sample size is the number of pixels in either dimension that correspond to a single pixel in the decoded bitmap. For example, inSampleSize == 4 returns an image that is 14 the widthheight of the original, and 116 the number of pixels. Any value &lt;= 1 is treated the same as 1. Note: the decoder uses a final value based on powers of 2, any other value will be rounded down to the nearest power of 2." />
      <item value="Keep aspect ratio if one dimension is set to 0" />
      <item value="compress" />
      <item value="ExifInterface supports the HEIF format on OMR1+. Glide's {@link DefaultImageHeaderParser} doesn't currently support HEIF. In the future we should reconcile these two classes, but for now this is a simple way to ensure that HEIF files are oriented correctly on platforms where they're supported." />
      <item value="Stop the heif writer synchronously. Throws exception if the writer didn't finish writing successfully. Upon a success return: - For buffer and bitmap inputs, all images sent before stop will be written. - For surface input, images with timestamp on or before that specified in {@link setInputEndOfStreamTimestamp(long)} will be written. In case where {@link setInputEndOfStreamTimestamp(long)} was never called, stop will block until maximum number of images are received. @param timeoutMs Maximum time (in microsec) to wait for the writer to complete, with zero indicating waiting indefinitely. @see setInputEndOfStreamTimestamp(long) @throws Exception if encountered error, in which case the output file may not be valid. In particular, {@link TimeoutException} is thrown when timed out, and {@link MediaCodec.CodecException} is thrown when encountered codec error." />
      <item value="synchronously" />
      <item value="oval" />
      <item value="transparent" />
      <item value="透明" />
      <item value="Called when a load completes successfully, immediately before" />
      <item value="14:05 File type recognized: File extension .analysis_options was reassigned to YAML Revert" />
      <item value="Accelerate Decelerate Interpolator" />
      <item value="exclude From Recents" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="910" />
        <entry key="ENGLISH" value="911" />
        <entry key="ESTONIAN" value="1" />
        <entry key="AFRIKAANS" value="1" />
        <entry key="DANISH" value="4" />
        <entry key="GERMAN" value="1" />
        <entry key="FRENCH" value="2" />
        <entry key="DUTCH" value="1" />
        <entry key="CATALAN" value="1" />
        <entry key="LATIN" value="2" />
        <entry key="ROMANIAN" value="1" />
        <entry key="BENGALI" value="2" />
        <entry key="PORTUGUESE" value="2" />
        <entry key="ITALIAN" value="1" />
        <entry key="INDONESIAN" value="1" />
      </map>
    </option>
  </component>
  <component name="Cache">
    <option name="lastTrimTime" value="1629250197797" />
  </component>
</application>